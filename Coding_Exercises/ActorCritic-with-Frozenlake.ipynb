{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic with OpenAI Gym\n",
    "\n",
    "\n",
    "This tutorial was inspired by [Outlace's excelent blog entry on Q-Learning](http://outlace.com/Reinforcement-Learning-Part-3/) and this is the [starting point](https://www2.informatik.uni-hamburg.de/~weber/code/ActorCritic.py) for my Actor Critic implementation. I highly recommend you read his three tutorials on Reinforcement Learning first.\n",
    "\n",
    "I got interested in Actor-Critic reinforcement learning after skimming DeepMind's follow-up to their original Atari paper. The new paper [Asynchronous Methods for Deep Reinforcement Learning](http://arxiv.org/abs/1602.01783) uses an Actor/Critic learning implementation to surpass the performance of their original Deep Q-Network. I couldn't find a good straightforward implementation/example of it.\n",
    "\n",
    "For a slightly more in-depth explination check out [Actor-Critic Methods](https://webdocs.cs.ualberta.ca/~sutton/book/ebook/node66.html) from the book 'Reinforcement Learning: An Introduction' by Sutton and Barto\n",
    "\n",
    "This will be a basic example of using Actor Critic methods to solve a simple reinforcement learning problem from OpenAI Gym\n",
    "\n",
    "Couple thing's we have here:\n",
    "\n",
    "* Actor Critic\n",
    "* Neural Networks as Function Approximators for both Actor and Critic\n",
    "* Experience Replay to avoid catastrophic forgetting\n",
    "\n",
    "If you are running the ipython notebook this tutorial expects you to have [OpenAI Gym](https://gym.openai.com/docs) and [Keras](https://github.com/fchollet/keras) installed. [The Notebook is available from GitHub](https://github.com/gregretkowski/notebooks/blob/master/ActorCritic-with-OpenAI-Gym.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets get to coding...\n",
    "\n",
    "We are going to start off with some bookkeeping - importing the components we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "# Just some initial setup and imports\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the environment our agent is going to interact with we'll use the OpenAI Gym, and use a variation of an existing environment 'Frozen Lake' - however we're going to make a version which does not include slippery ice. This simplification will make it much easier to visualize what's happening within our Actor/Critic implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-04 16:56:55,969] Making new env: FrozenLakeNonskid8x8-v0\n"
     ]
    }
   ],
   "source": [
    "# Create a non-skid version of Frozen Lake\n",
    "from gym.envs.registration import register, spec\n",
    "\n",
    "MY_ENV_NAME='FrozenLakeNonskid8x8-v0'\n",
    "try:\n",
    "    spec(MY_ENV_NAME)\n",
    "except:\n",
    "    register(\n",
    "        id=MY_ENV_NAME,\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={'map_name': '8x8', 'is_slippery': False},\n",
    "        timestep_limit=100,\n",
    "        reward_threshold=0.78, # optimum = .8196\n",
    "    )\n",
    "env = gym.make(MY_ENV_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll define some constants, to make the code clearer and easier later. The constants ```OBSERVATION_SPACE``` and ```ACTION_SPACE``` come from OpenAI gym. For this problem each of these is just a single integer. I then define a constant ```OBS_SQR``` and ```STATEGRID``` which will help when we create visualizations showing the square grid of our gridworld. These constants are not needed for the learner.\n",
    "\n",
    "Finally I create a helper which will allow us to convert the observation from OpenAI Gym, from an integer, like 64, to a one-hot encoding - which is better for a neural network to consume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This helper is for later. \n",
    "def to_onehot(size,value):\n",
    "  my_onehot = np.zeros((size))\n",
    "  my_onehot[value] = 1.0\n",
    "  return my_onehot\n",
    "\n",
    "OBSERVATION_SPACE = env.observation_space.n\n",
    "ACTION_SPACE = env.action_space.n\n",
    "\n",
    "# Assume gridworld is always square\n",
    "OBS_SQR= int(math.sqrt(OBSERVATION_SPACE))\n",
    "STATEGRID = np.zeros((OBS_SQR,OBS_SQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATEGRID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Actor\n",
    "\n",
    "In Actor/Critic there are two networks. The Policy network (the Actor) and the Value network (the Critic). You will recognize the policy network as being essentially the same as the network from the Q-Learning example referenced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/gmunoz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(164, input_shape=(64,), kernel_initializer=\"lecun_uniform\")`\n",
      "/home/gmunoz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(150, kernel_initializer=\"lecun_uniform\")`\n",
      "/home/gmunoz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"lecun_uniform\")`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "\n",
    "actor_model = Sequential()\n",
    "actor_model.add(Dense(164, init='lecun_uniform', input_shape=(OBSERVATION_SPACE,)))\n",
    "actor_model.add(Activation('relu'))\n",
    "\n",
    "actor_model.add(Dense(150, init='lecun_uniform'))\n",
    "actor_model.add(Activation('relu'))\n",
    "\n",
    "actor_model.add(Dense(ACTION_SPACE, init='lecun_uniform'))\n",
    "actor_model.add(Activation('linear'))\n",
    "\n",
    "a_optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "actor_model.compile(loss='mse', optimizer=a_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Critic\n",
    "Next, we set up the Critic network. This network looks very similar to the Actor model, but only outputs a single value - it outputs a value (the score) for the input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmunoz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(164, input_shape=(64,), kernel_initializer=\"lecun_uniform\")`\n",
      "/home/gmunoz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(150, kernel_initializer=\"lecun_uniform\")`\n",
      "/home/gmunoz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"lecun_uniform\")`\n"
     ]
    }
   ],
   "source": [
    "critic_model = Sequential()\n",
    "\n",
    "critic_model = Sequential()\n",
    "critic_model.add(Dense(164, init='lecun_uniform', input_shape=(OBSERVATION_SPACE,)))\n",
    "critic_model.add(Activation('relu'))\n",
    "critic_model.add(Dense(150, init='lecun_uniform'))\n",
    "critic_model.add(Activation('relu'))\n",
    "critic_model.add(Dense(1, init='lecun_uniform'))\n",
    "critic_model.add(Activation('linear'))\n",
    "\n",
    "c_optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "critic_model.compile(loss='mse', optimizer=c_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll add a nice helper function to show what value the Critic gives to being in certain states. The critic starts out uninitialized and will just give random values for any given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu0XlV97vHvw064GLkaiTFgiTZFU4eNNAWs9yIaUAme\nUS1UkWNtIz2iYqueqKNHatszOF57HKXkRI0G5VIE0ZSmYKQgtV6agCl3JCKYxEAMFLkp5PKcP9bc\n+rq7L2tnv++7dvZ6PmOssdd9/t6Mnd8791xzzSnbREREO+zVdAAREdE/SfoRES2SpB8R0SJJ+hER\nLZKkHxHRIkn6EREtkqQf4yLpCEmWNK3pWJok6VpJf9x0HBHjlaTfMpKulPThYfYvlnRvk8lc0t2S\ntkqa0bHvjyVdW/P6z0v6654FGDEFJOm3z0rgTZI0ZP9pwAW2dzQQU6cB4F0NxzAiVfL/JvZY+eVt\nn68ATwFePLhD0sHAa4Dzy/arJX1P0kOSNko6e6Sbldr5Kzq2z5b0xY7tYyV9S9KDkv5D0svGiO+j\nwHskHTRCec+WtEbSA5LukPSGsn8J8EbgfZIekfSPkt4i6R87rr1T0pc6tjdKWlDWf1fSWkk/LT9/\nt+O8ayX9jaR/Ax4DnjkkptmSbpT03jE+W0TjkvRbxvbPgEuAN3fsfgNwu+3/KNuPluMHAa8G/lTS\nyeMtS9Ic4J+AvwYOAd4DXCbpqaNctg64tpw79H4zgDXAhcChwCnA30uab3s5cAHwEdtPtv1a4BvA\niyXtJenpwN7AC8q9ngk8GbhR0iElzk9RfSF+AvgnSU/pKP40YAmwP3BPR0xzSzl/Z/uj4/jniWhE\nkn47rQR+X9K+ZfvNZR8Atq+1fZPtXbZvBC4CXrob5bwJWG17dbnXGqqkfuIY1/0v4B3DfDm8Brjb\n9uds77D9PeAy4PXD3cT2XcDDwALgJcBVwI8lPbt8nn+1vYvqi+1O218o970IuB14bcftPm/7lnJ8\ne9k3H7gG+FD50omY9FrdA6OtbH9T0jbgZElrgaOB/zZ4XNIxwDnAc6lqx/sAXxruXmP4NeD1kjqT\n53SqRDlafDdLugJYCtw25H7HSHqwY9804Auj3O4bwMuAXy/rD1Il/BeUbYCn01F7L+4B5nRsbxzm\n3m8ENgCXjlJ+xKSSmn57nU9Vw38TcJXt+zqOXQisAg63fSCwDBj64HfQo8CTOraf1rG+EfiC7YM6\nlhm2z6kR34eAP+G/Jt5vDLnfk23/aTk+3JCxg0n/xWX9G1RJ/6X8Mun/mOoLpdMzgM0d28Pd+2xg\nG3ChpIEanymicUn67XU+8AqqxLpyyLH9gQds/1zS0cAfjnKf9cApkqZLWgj8fsexLwKvlfQqSQOS\n9pX0MkmHjRWc7Q3APwDv7Nh9BfAbkk4r5U2X9DuSnlOO38eQh6xUif3lwH62NwH/Ciyiarv/Xjln\ndbnvH0qaJukPqJpurhgjzO1UTUszgPPTqyf2BPklbSnbdwPfokpYq4Yc/h/AhyU9TNW+fskot/oL\n4FnAfwJ/SfVXwmAZG4HFwAeAn1DV1N9L/d+7D5f4Bu/3MPBKqge4PwbuBf4PVfMTwGeB+aWn0FfK\nNd8HHqFK9th+CLgL+DfbO8u++6meF/w5cD/wPuA1treNFaDtJ6iaxmYBK5L4Y7JTJlGJiGiP1Eoi\nIlqkp0lf0qLyAs0GSUt7WVZERIytZ807pTfD94HjgU3AWuBU27f2pMCIiBhTL2v6RwMbbN9VHnZd\nTPVQLyIiGtLLl7Pm8KsvtGwCjhl6UhkzZQmA9t77t6fPOrSHIY1t4OeNFg/AXgdtH/ukPpi59yNN\nh8CWR4YdgqevtH2kVxT6bN9dTUfAPtObHo+v8tAdW7fZHm04jzG96uUzfP8DO2ude/2Nj19le9FE\nypssGn8jt7y+vhxgn2cc7qe/76xG4znw9uafbT/55C1NhwDAHz3jW02HwF9+86SmQ2DfzdObDgEA\nz2/+S/hZTx2zF2tfXPnSTw19g3rc7n9gJ/9+1TNqnTsw+86ZEy1vsuhl0t8MHN6xfRi/+oZjRERj\nDOyi+b+e+q2XSX8tMK+MQriZ6oWa0d7sjIjoG2O2u17zzlTSs6Rve4ekM6lGNhwAVti+pVflRUSM\nV2r6XWZ7NdW4JhERk4oxO1s4IkHjD3IjIpqya9jBU6e2JP2IaCUDO5P0IyLaIzX9iIiWMLC9hW36\nzb+JFBHRAGN21lzqGGuASUnPlvRtSY9Les+QY3dLuknSeknrOvYfImmNpDvLz4Mn+rmT9COinQw7\nay5jKQNMngucQDXr2qmS5g857QGqmeA+NsJtXm57ge2FHfuWAlfbngdcXbYnJEk/IlqpeiO33lLD\nmANM2t5qey3VNJt1LeaX05muBE4ex7XDStKPiJYSO2suNQw3wOSccQRj4OuSri+DUA6aZXtwMK57\nqablnJA8yI2IVqoe5NYeQXVmZ1s7sLwMFtktL7K9WdKhwBpJt9u+rvME25Y04SfPSfoR0UpVP/3a\nSX/bkLb2oSY0wKTtzeXnVkmXUzUXXQfcJ2m27S2SZgNb695zJGneiYjW2mXVWmr4xQCTkvamGmBy\nVZ0LJc2QtP/gOvBK4OZyeBVwelk/HfjqOD7esFLTj4hWGmdNf/R7jTDApKQzyvFlkp4GrAMOAHZJ\nOouqp89M4HJJUOXkC21fWW59DnCJpLcC9wBvmGisSfoR0UpG7OxiY8dwA0zaXtaxfi9Vs89QDwG/\nNcI97weO61qQJOlHRIvVbLqZUpL0I6KVjHjCA02H0XdJ+hHRStXLWe3ry5KkHxGt1a0HuXuSJP2I\naCVb7HT7avo9+8SSVkjaKunmsc+OiOi/XajWMpX08mvu88CiHt4/ImK3VQ9yp9VappKefRrb10k6\nolf3j4iYiDzInQQOPeCnvPO4qxqN4fLnDPuORF8duPfPmw4BgA9/67VNh8D8c+5vOgT2/dwjTYcA\nwP0/f1LTIfCkaeMZFXjy25l++v1XhhFdAnDw7H0bjiYi2qLbb+TuKRr/xLaX215oe+GMQ6Y3HU5E\ntMgu71VrmUoar+lHRDShGnBtaiX0OnrZZfMi4NvAkZI2lVHiIiImBSO2e6DWMpX0svfOqb26d0TE\nRNm08uWsNO9EREtNvRev6kjSj4hWMu2s6bfvE0dEFDvZq9ZSh6RFku6QtEHS0mGOP1vStyU9Luk9\nHfsPl3SNpFsl3SLpXR3Hzpa0WdL6spw40c+cmn5EtJKpPf/tmCQNAOcCxwObgLWSVtm+teO0B4B3\nAicPuXwH8Oe2byhz5V4vaU3HtZ+0/bGuBEpq+hHRUga2e1qtpYajgQ2277L9BHAxsPhXyrO32l4L\nbB+yf4vtG8r6w8BtwJwufMRhJelHREuJnTWXGuYAGzu2N7EbibuMV/Z84Lsdu98h6cYycvHB473n\nUEn6EdFKZlxv5M6UtK5jWdLteCQ9GbgMOMv2Q2X3ecAzgQXAFuDjEy0nbfoR0VrjmDlrm+2Foxzf\nDBzesX1Y2VeLpOlUCf8C218e3G/7vo5zPg1cUfeeI0lNPyJayVY3x95ZC8yTNFfS3sApwKo6F0oS\n8FngNtufGHJsdsfm64AJT0qVmn5EtFL1ILc7QyzY3iHpTOAqYABYYfsWSWeU48skPQ1YBxwA7JJ0\nFjAfeB5wGnCTpPXllh+wvRr4iKQFJdy7gbdNNNYk/Yhoqe7OkVuS9Ooh+5Z1rN9L1ewz1Ddh+HYm\n26d1LcAiST8iWql6kJthGCIiWqONQysn6UdEK3Xzjdw9SZJ+RLRWJkaPiGgJG7bvStKPiGiFqnkn\nST8iojXG8UbulJGkHxGt1NYum72cGH3EiQEiIprX1WEY9hi9rOmPNTFARESjMkduF9neQjUUKLYf\nljQ4McCISf8n/3kgyy49oVch1fLG113TaPkAXzn35U2HAMD++zUdAXzumi80HQLHfvXPmg4BgIGf\nNV/jfNZLbmo6hK6peu90Z+ydPUlf2vRHmBhg8NgSYAnAtAMnPD9AREQtbX05q+dVhxEmBvgF28tt\nL7S9cGDGjF6HExHxC7tQrWUq6WlNf6SJASIimtbW3js9S/qjTQwQETEZTLWeOXX0sqb/QkaeGCAi\nolG22NHCpN+zT2z7m7Zl+3m2F5QlCT8iJo1dVq2lDkmLJN0haYOkpcMcf7akb0t6XNJ76lwr6RBJ\nayTdWX5OuLdL+77mIiL4ZZt+N5K+pAHgXOAEqikQT5U0f8hpDwDvBD42jmuXAlfbngdcXbYnJEk/\nIlqrizX9o4ENtu+y/QRwMbC48wTbW22vBbaP49rFwMqyvhI4efc+6S8l6UdEKw320+9S0p8DbOzY\n3lT2TfTaWeVFV4B7gVk17zmiDLgWEa01jj74MyWt69hebnt5D0IakW1L8kTvk6QfEa1kw476k6hs\ns71wlOObgcM7tg8r++oY7dr7JM22vUXSbGBr3YBHkuadiGitLjbvrAXmSZoraW/gFGBVzTBGu3YV\ncHpZPx34au0PN4LU9COilbo59o7tHZLOBK4CBoAVtm+RdEY5vkzS04B1wAHALklnAfNtPzTcteXW\n5wCXSHorcA/whonGmqQfEa3lLg7DUN5DWj1k37KO9Xupmm5qXVv23w8c17UgSdKPiBabaoOp1ZGk\nHxGtZGfAtYiIFhE76/femTKS9COitbrZpr+nSNKPiFbKePoREW3iql2/bZL0I6K10nsnIqIlnAe5\nERHtkuadiIgWSe+dLpK0L3AdsE8p51LbH+pVeRER42En6Xfb48Dv2X5E0nTgm5L+2fZ3elhmRERt\n6bLZRbYNPFI2p5dl1Ba0vXbAPg/0KqJ6vv7BFzcbAPDuj/1D0yEA8KG1JzUdAi9f9t6mQ2A/YNrv\nPNh0GBz0uf2bDoHrNz+v6RC6qo1t+j19dC1pQNJ6qoH/19j+7jDnLJG0TtK6HT97tJfhROyWyZDw\no/uM2LVrr1rLVNLTT2N7p+0FVMOJHi3pucOcs9z2QtsLp+03o5fhRET8CtdcppK+fIXZfhC4BljU\nj/IiIsZUHuTWWaaSniV9SU+VdFBZ3w84Hri9V+VFRIxbF6v6khZJukPSBklLhzkuSZ8qx2+UdFTZ\nf6Sk9R3LQ2VWLSSdLWlzx7ETJ/qRe9l7ZzawUtIA1ZfLJbav6GF5ERHj0q1afMlz51JVbjcBayWt\nsn1rx2knAPPKcgxwHnCM7TuABR332Qxc3nHdJ21/rCuB0tveOzcCz+/V/SMiJsLArl1da7o5Gthg\n+y4ASRcDi4HOpL8YOL/0bPyOpIMkzba9peOc44Af2L6nW4ENNbUeS0dE1GXAqreMbQ6wsWN7U9k3\n3nNOAS4asu8dpTlohaSD6wQzmiT9iGgtu94CzBzsWl6WJd2ORdLewEnAlzp2nwc8k6r5Zwvw8YmW\nk7F3IqK96vfH3GZ74SjHNwOHd2wfVvaN55wTgBts3/eL8DrWJX0amPBz0dT0I6Kl6nXXrPmwdy0w\nT9LcUmM/BVg15JxVwJtLL55jgZ8Oac8/lSFNO5Jmd2y+Drh5vJ9yqNT0I6K9uvTmle0dks4ErgIG\ngBW2b5F0Rjm+DFgNnAhsAB4D3jJ4vaQZVD1/3jbk1h+RtKBEevcwx8ctST8i2sng7vXewfZqqsTe\nuW9Zx7qBt49w7aPAU4bZf1rXAiyS9COixabW27Z1JOlHRHtNtYF1akjSj4j2StKPiGiJwZezWiZJ\nPyJaq42TqCTpR0R7dbH3zp4iST8iWkup6UdEtMRUnBarhiT9iGip2iNoTilJ+hHRXqnpR0S0yK6m\nA+i/JP2IaKeW9tPv+dDKkgYkfU9S5seNiElFrrdMJSMmfUmrJR3RhTLeBdzWhftERHSXay5TyGg1\n/c8BX5P0QUnTd+fmkg4DXg18Zneuj4iI7hqxTd/2lyT9M/AXwDpJX6DjsYftT9S4/98C7wP2H+mE\nMtfkEoBpMw/k0WMfqxl6b+x82fZGywc49+zXNx0CAPOWbBz7pB7bdu2vNR0Ch5x8a9MhAPDECb/T\ndAg8PHdqtYFPtaabOsZq038CeBTYhypxdy6jkvQaYKvt60c7z/Zy2wttL9zrgBn1oo6ImChTDcNQ\nZ6lB0iJJd0jaIGnpMMcl6VPl+I2Sjuo4drekmyStl7SuY/8hktZIurP8PHiiH3vEmr6kRcAnqOZ1\nPMr2eKvgLwROknQisC9wgKQv2n7TbkcbEdFNXarpSxoAzqWa8nATsFbSKtudfyaeAMwryzHAeeXn\noJfb3jbk1kuBq22fU75IlgL/cyKxjlbT/yDwettLdyPhY/v9tg+zfQTVJMH/koQfEZNJF3vvHA1s\nsH2X7SeAi4HFQ85ZDJzvyneAg4ZMfD6cxcDKsr4SOLn2hxvBiEnf9ott3zLRAiIiJq3u9d6ZA3Q+\nBNtU9tU9x8DXJV1fnnMOmmV7S1m/F5hVK5pR9OXlLNvXAtf2o6yIiNrqN+/M7GxrB5bbXt7FSF5k\ne7OkQ4E1km63fV3nCbYtTfzRc97IjYhWGueLV9tsLxzl+Gbg8I7tw8q+WufYHvy5VdLlVM1F1wH3\nSZpte0tpCtpaO+IR9PyN3IiISat7vXfWAvMkzZW0N9VzzFVDzlkFvLn04jkW+GlJ5jMk7Q8gaQbw\nSuDmjmtOL+unA1+d2AdOTT8iWqxb/fRt75B0JnAVMACssH2LpDPK8WXAauBEYAPwGPCWcvks4HJJ\nUOXkC21fWY6dA1wi6a3APcAbJhprkn5EtFcXX86yvZoqsXfuW9axbuDtw1x3F/BbI9zzfuC47kWZ\npB8RbTUFB1OrI0k/ItorST8ioj3UwklU0nsnIqJFUtOPiPZK805EREvkQW5ERMsk6UdEtEiSfkRE\nO4h29t5J0o+IdkqbfkREyyTpR0S0SJJ+RER7pHknIqJNkvS7S9LdwMPATmDHGDPPRET0j9N7p1de\nbntbH8qJiBifFtb0M+BaRLTW4Dy5Yy217iUtknSHpA2Slg5zXJI+VY7fKOmosv9wSddIulXSLZLe\n1XHN2ZI2S1pflhMn+pl7XdM38HVJO4H/N9zs8ZKWAEsA9tUMfv2t3+9xSJPf87/1aNMhAPC/D72x\n6RB49itPazoEHjp+2EmN+u65T7+n6RC4+7Yjmg6hu7pU05c0AJwLHA9sAtZKWmX71o7TTgDmleUY\n4Lzycwfw57ZvKHPlXi9pTce1n7T9se5E2vuk/yLbmyUdCqyRdLvt6zpPKF8EywEOHJjZwj+2IqIR\nppvNO0cDG8rUh0i6GFgMdCb9xcD5ZdrE70g6SNJs21uALQC2H5Z0GzBnyLVd09PmHduby8+twOVU\n/zAREY0T42remSlpXceyZMjt5gAbO7Y3lX3jOkfSEcDzge927H5HaQ5aIeng3fy4v9CzpC9pRvlT\nBUkzgFcCN/eqvIiI8RpH0t9me2HH8l+aqicci/Rk4DLgLNsPld3nAc8EFlD9NfDxiZbTy+adWcDl\nkgbLudD2lT0sLyJifLrXvLMZOLxj+7Cyr9Y5kqZTJfwLbH/5F+HZ9w2uS/o0cMVEA+1Z0i9tW5Pj\nCVhExHC6l/TXAvMkzaVK5KcAfzjknFXAmaW9/xjgp7a3qKoZfxa4zfYnOi/oaPMHeB1daC3JG7kR\n0U5dHGXT9g5JZwJXAQPACtu3SDqjHF8GrAZOBDYAjwFvKZe/EDgNuEnS+rLvA7ZXAx+RtKCKlruB\nt0001iT9iGivLvYXLEl69ZB9yzrWDbx9mOu+SfVcebh7dr3PcpJ+RLRWhmGIiGiRjLIZEdEW3X05\na4+RpB8R7ZWkHxHRDoNv5LZNkn5EtJZ2tS/rJ+lHRDulTT8iol3SvBMR0SZJ+hER7ZGafkREmyTp\nR0S0hDMMQ0REa6SffkRE27h9WT9JPyJaKzX9iIi2aOnLWT2bGB1A0kGSLpV0u6TbJL2gl+VFRIyH\ndtVbat1LWiTpDkkbJC0d5rgkfaocv1HSUWNdK+kQSWsk3Vl+HjzRz9zTpA/8X+BK28+mmi/3th6X\nFxFRW7eSvqQB4FzgBGA+cKqk+UNOOwGYV5YlwHk1rl0KXG17HnB12Z6QniV9SQcCL6Ga8BfbT9h+\nsFflRUSMi6ke5NZZxnY0sMH2XbafAC4GFg85ZzFwvivfAQ6SNHuMaxcDK8v6SuDkCX1metumPxf4\nCfA5Sb8FXA+8y/ajnSdJWkL1rce+0w9Az3pGD0Ma27EX3Nho+QDfe/DwpkMA4KiNz2k6BA69cL+m\nQ+ChIwaaDgGA+zY/s+kQOPJHjzUdAgA/6tJ9xvEgd6akdR3by20v79ieA2zs2N4EHDPkHsOdM2eM\na2fZ3lLW7wVm1Y54BL1s3pkGHAWcZ/v5wKMM86eJ7eW2F9peuPe0GT0MJyJiCNdcYNtgnirL8uFv\n2MNQq4nVJ/zouZdJfxOwyfZ3y/alVF8CERGNG3w5q85Sw2ag80/0w8q+OueMdu19pQmI8nNrzY83\nop4lfdv3AhslHVl2HQfc2qvyIiLGxUa76i01rAXmSZoraW/gFGDVkHNWAW8uvXiOBX5amm5Gu3YV\ncHpZPx346sQ+dO/76b8DuKB8kLuAt/S4vIiI+rrUT9/2DklnAlcBA8AK27dIOqMcXwasBk4ENgCP\nUfLhSNeWW58DXCLprcA9wBsmGmtPk77t9cDCXpYREbG7uvlGru3VVIm9c9+yjnUDb697bdl/P1Ur\nSdfkjdyIaCcDmSM3IqJF2pfzk/Qjor0y4FpERIvU7JkzpSTpR0Q7tXSUzST9iGil6uWs9mX9JP2I\naK/MkRsR0R6p6UdEtEXa9CMi2qT2uDpTSpJ+RLRXmnciIlrC9ee/nUqS9COivVLTj4hokfbl/CT9\niGgv7Wpf+06SfkS0k2nly1m9nCM3ImLSEkaut0yoHOkQSWsk3Vl+HjzCeYsk3SFpg6SlHfs/Kul2\nSTdKulzSQWX/EZJ+Jml9WZYNd9+hkvQjor3sesvELAWutj0PuLps/wpJA8C5wAnAfOBUSfPL4TXA\nc20/D/g+8P6OS39ge0FZzqgTTM+SvqQjO76B1kt6SNJZvSovImLc+pP0FwMry/pK4ORhzjka2GD7\nLttPABeX67D9Nds7ynnfAQ6bSDA9S/q27xj8BgJ+m2oi4Mt7VV5ExLgMtunXWWCmpHUdy5JxlDTL\n9payfi8wa5hz5gAbO7Y3lX1D/RHwzx3bc0ul+huSXlwnmH49yD2O6s+Qe/pUXkTEmMbRe2eb7YUj\n3kf6OvC0YQ59sHPDtqXdm69L0geBHcAFZdcW4Bm275f028BXJP2m7YdGu0+/kv4pwEVjnfTzpwxw\n55uHfcbRN3d+7aWNlg+wz/1qOgQA5r7qh02HwPePPqTpECbRW5vNP4I78O3bmg6h0pX/pl1puqnu\nZL9ipGOS7pM02/YWSbOBrcOcthk4vGP7sLJv8B7/HXgNcJxdBW37ceDxsn69pB8AvwGsGy3Wnv8W\nSdobOAn40gjHlwz+ybTr0Ud7HU5ERMX0q01/FXB6WT8d+Oow56wF5kmaW3LmKeU6JC0C3gecZPux\nwQskPbU8AEbSM4F5wF1jBdOPqsMJwA227xvuoO3lthfaXrjXjBl9CCcioqjfpj8R5wDHS7oTeEXZ\nRtLTJa0GKA9qzwSuAm4DLrF9S7n+74D9gTVDuma+BLhR0nrgUuAM2w+MFUw/mndOpUbTTkREv/Vj\nEhXb91M91xy6/8fAiR3bq4HVw5z36yPc9zLgsvHG09OavqQZwPHAl3tZTkTEbulP886k0tOavu1H\ngaf0soyIiN1iw85J85S+bzL2TkS01xSrxdeRpB8R7ZWkHxHREgYyR25ERFsYnDb9iIh2MHmQGxHR\nKmnTj4hokST9iIi2mHovXtWRpB8R7WQgE6NHRLRIavoREW2RYRgiItrD4PTTj4hokbyRGxHRIi1s\n029+0s2IiCbYVe+dOssESDpE0hpJd5afw04ELmmRpDskbZC0tGP/2ZI2l1mz1ks6sePY+8v5d0h6\nVZ14kvQjor36M4nKUuBq2/OAq8v2ryhz3Z5LNb3sfOBUSfM7Tvmk7QVlWV2umU81l+5vAouAvx+c\nM3c0SfoR0VLGO3fWWiZoMbCyrK8ETh7mnKOBDbbvsv0EcHG5bqz7Xmz7cds/BDaU+4wqST8i2mlw\naOU6C8yUtK5jWTKOkmbZ3lLW7wVmDXPOHGBjx/amsm/QOyTdKGlFR/PQWNcMKw9yI6K96nfZ3GZ7\n4UgHJX0deNowhz74K8XZljTe9qLzgL+i+pr6K+DjwB+N8x6/0NOkL+ndwB9TBXsT8BbbP+9lmRER\ndRhwl7ps2n7FSMck3Sdptu0tkmYDW4c5bTNweMf2YWUftu/ruNengSvGumY0PWvekTQHeCew0PZz\ngQGqhw4REc1zmUSlzjIxq4DTy/rpwFeHOWctME/SXEl7U+XKVQDli2LQ64CbO+57iqR9JM0F5gH/\nPlYwvW7emQbsJ2k78CTgxz0uLyKiti48pK3jHOASSW8F7gHeACDp6cBnbJ9oe4ekM4GrqCrIK2zf\nUq7/iKQFVH+c3A28DcD2LZIuAW4FdgBvtz3mB5J7+HKCpHcBfwP8DPia7TcOc84SYPChyHP55bdY\nU2YC2xqOASZHHInhlyZDHJMhBpgccRxpe/+J3EDSlVSfpY5tthdNpLzJomdJvzxhvgz4A+BB4EvA\npba/OMo160Z7WNIPkyGGyRJHYphccUyGGCZLHJMhhj1VL7tsvgL4oe2f2N4OfBn43R6WFxERY+hl\n0v8RcKykJ0kScBxwWw/Li4iIMfQs6dv+LnApcANVd829gOVjXDbW8X6YDDHA5IgjMfzSZIhjMsQA\nkyOOyRDDHqmnD3IjImJyyTAMEREtkqQfEdEikyLpjzSOdJ9jWCFpq6TG3hOQdLikayTdKumW8p5D\nE3HsK+nfJf1HieMvm4ijxDIg6XuSrhj77J7FcLekm8pY5usaiuEgSZdKul3SbZJe0EAMR3aM6b5e\n0kOSzmogjneX38ubJV0kad9+x7Ana7xNv4z//H3geKpR4tYCp9q+tc9xvAR4BDi/DBvRd+V169m2\nb5C0P3CbETpWAAADbklEQVQ9cHID/xYCZth+RNJ04JvAu2x/p59xlFj+DFgIHGD7Nf0uv8RwN9Vw\nIo29kCRpJfCvtj9TXtN/ku0HG4xngGqcl2Ns39PHcudQ/T7Ot/2z8kbqatuf71cMe7rJUNPfnXGk\nu872dcAD/S53SAxbbN9Q1h+m6uI65lCpPYjDth8pm9PL0vfagaTDgFcDn+l32ZOJpAOBlwCfBbD9\nRJMJvzgO+EE/E36HweFdppHhXcZtMiT93RoTeqqTdATwfOC7DZU/IGk91YiAa0oX3H77W+B9wIRH\nvJogA1+XdP04x1HvlrnAT4DPlaauz0ia0UAcnU4BLup3obY3Ax+jeg9oC/BT21/rdxx7ssmQ9GMI\nSU+mGsLiLNsPNRGD7Z22F1AN13q0pL42eUl6DbDV9vX9LHcELyr/FicAby9Ngf00DTgKOM/284FH\nGWbKvX4pzUsnUQ2t0u+yD6ZqCZgLPB2YIelN/Y5jTzYZkv5ujQk9VZU29MuAC2x/uel4SjPCNVRz\ncPbTC4GTSnv6xcDvSRpx3KZeKrVLbG8FLqfGlHRdtgnY1PHX1qVUXwJNOQG4oXOc9z7K8C4TNBmS\n/ojjSLdNeYD6WeA2259oMI6nSjqorO9H9ZD99n7GYPv9tg+zfQTV78S/2O57jU7SjPJQndKk8kr6\nPBKs7XuBjZKOLLuOoxpOtymn0kDTTpHhXSao8ekSxxhHum8kXQS8jGouzE3Ah2x/ts9hvBA4Dbip\ntKcDfMD26j7HMRtYWXpo7AVcYruxLpMNmwVcXuUXpgEX2r6ygTjeAVxQKkZ3AW9pIIbBL77jKWO6\n95vt70oaHN5lB/A9MiTDuDTeZTMiIvpnMjTvREREnyTpR0S0SJJ+RESLJOlHRLRIkn5ERIsk6cek\nU0Yb/aGkQ8r2wWX7iGYji9jzJenHpGN7I3AecE7ZdQ6w3PbdjQUVMUWkn35MSmU4iuuBFcCfAAvK\na/cRMQGNv5EbMRzb2yW9F7gSeGUSfkR3pHknJrMTqIbPbWRSm4ipKEk/JiVJC6jGeDkWeHeZVSwi\nJihJPyadMnrieVTzCfwI+CjVxBkRMUFJ+jEZ/QnwI9tryvbfA8+R9NIGY4qYEtJ7JyKiRVLTj4ho\nkST9iIgWSdKPiGiRJP2IiBZJ0o+IaJEk/YiIFknSj4hokf8P5CKmfN/mgU0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd06a8d4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot out the values the critic gives for the agent being in\n",
    "# a specific state, i.e. in a specific location in the env.\n",
    "def plot_value(initial_state):\n",
    "    # Assume gridworld is always a square\n",
    "    obs_sqr = math.sqrt(OBSERVATION_SPACE)\n",
    "    np_w_cri_r = np.zeros((OBS_SQR,OBS_SQR))\n",
    "    # make a working copy.\n",
    "    working_state = initial_state.copy()\n",
    "    for x in range(0,OBS_SQR):\n",
    "        for y in range(0,OBS_SQR):\n",
    "            my_state = working_state.copy()\n",
    "            # Place the player at a given X/Y location.\n",
    "            my_state[x,y] = 1\n",
    "            # And now have the critic model predict the state value\n",
    "            # with the player in that location.\n",
    "            value = critic_model.predict(my_state.reshape(1, OBSERVATION_SPACE))\n",
    "            np_w_cri_r[x,y] = value\n",
    "    np_w_cri_r.shape\n",
    "    pylab.pcolor(np_w_cri_r)\n",
    "    pylab.title(\"Value Network\")\n",
    "    pylab.colorbar()\n",
    "    pylab.xlabel(\"X\")\n",
    "    pylab.ylabel(\"Y\")\n",
    "    pylab.gca().invert_yaxis()\n",
    "    pylab.draw()\n",
    "\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "plot_value(STATEGRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may not be necessary, or even possible in all cases - but in this case we can zero-out the Critic network, so that all states start with a value of Zero. This should help it converge later when it sees real training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroing out critic network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmunoz/anaconda3/lib/python3.6/site-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNm+RyvYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbce86adb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def zero_critic(epochs=100):\n",
    "    for i in range(epochs):\n",
    "        for j in range(OBSERVATION_SPACE):\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            \n",
    "            y = np.empty([1])\n",
    "            y[0]=0.0\n",
    "            x = to_onehot(OBSERVATION_SPACE,j)\n",
    "            X_train.append(x.reshape((OBSERVATION_SPACE,)))\n",
    "            y_train.append(y.reshape((1,)))\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "            critic_model.fit(X_train, y_train, batch_size=1, nb_epoch=1, verbose=0)\n",
    "\n",
    "print(\"Zeroing out critic network...\")\n",
    "sys.stdout.flush()\n",
    "zero_critic()\n",
    "print(\"Done!\")\n",
    "plot_value(STATEGRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Trainer\n",
    "\n",
    "The trainer is implemented below. \n",
    "\n",
    "The big main new things here are the split of the Critic network, and state values, from the Actor, and action selection.\n",
    "\n",
    "To train the critic network, we use a simlar process to training value into Q networks. We look at the initial state, make a move, and then look at the new state. For the value network, if we are in a terminal state, that's the value we tell the value network to place on that state. If we are in a non-terminal state, we tell the value network to place a value on the original state which is the reward in the original state, plus the discounted value from the new state. Note that the value network should return the maximum possible value for a given state. If the player's next move could be either jumping into the pit or arriving at the goal, we should set the value as if the best-possible action will be selected.\n",
    "\n",
    "After the critic network has assigned a value to the original and the new state, we adjust the policy. This is simply by looking at our value in our old state, and the value in the new state. If the value improves we encourage that action. If it decreases we discourage the action.\n",
    "\n",
    "When we start training, both the actor and the critic networks are spitting out nonsensical values. Which means initially the actor network is training on values from the critic network which are garbage. However as the critic network improves, those improvements naturally correct and improve the performance of the actor network.\n",
    "\n",
    "The Experience Replay is essentially the same as the example in the Q-learning tutorial. However we replay both the Actor and the Critic's experiences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import random\n",
    "import time\n",
    "\n",
    "def trainer(epochs=1000, batchSize=40, \n",
    "            gamma=0.975, epsilon=1, min_epsilon=0.1,\n",
    "            buffer=80):\n",
    "    \n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    # Replay buffers\n",
    "    actor_replay = []\n",
    "    critic_replay = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        reward = 0\n",
    "        info = None\n",
    "        move_counter = 0\n",
    "\n",
    "        while(not done):\n",
    "            # Get original state, original reward, and critic's value for this state.\n",
    "            orig_state = to_onehot(OBSERVATION_SPACE,observation)\n",
    "            orig_reward = reward\n",
    "            orig_val = critic_model.predict(orig_state.reshape(1,OBSERVATION_SPACE))\n",
    "\n",
    "            if (random.random() < epsilon): #choose random action\n",
    "                action = np.random.randint(0,ACTION_SPACE)\n",
    "            else: #choose best action from Q(s,a) values\n",
    "                qval = actor_model.predict( orig_state.reshape(1,OBSERVATION_SPACE) )\n",
    "                action = (np.argmax(qval))\n",
    "                \n",
    "            #Take action, observe new state S'\n",
    "            new_observation, new_reward, done, info = env.step(action)\n",
    "            new_state = to_onehot(OBSERVATION_SPACE,new_observation)\n",
    "            # Critic's value for this new state.\n",
    "            new_val = critic_model.predict(new_state.reshape(1,OBSERVATION_SPACE))\n",
    "            \n",
    "            if not done: # Non-terminal state.\n",
    "                target = orig_reward + ( gamma * new_val)\n",
    "            else:\n",
    "                # In terminal states, the environment tells us\n",
    "                # the value directly.\n",
    "                target = orig_reward + ( gamma * new_reward )\n",
    "            \n",
    "            # For our critic, we select the best/highest value.. The\n",
    "            # value for this state is based on if the agent selected\n",
    "            # the best possible moves from this state forward.\n",
    "            # \n",
    "            # BTW, we discount an original value provided by the\n",
    "            # value network, to handle cases where its spitting\n",
    "            # out unreasonably high values.. naturally decaying\n",
    "            # these values to something reasonable.\n",
    "            best_val = max((orig_val*gamma), target)\n",
    "\n",
    "            # Now append this to our critic replay buffer.\n",
    "            critic_replay.append([orig_state,best_val])\n",
    "            # If we are in a terminal state, append a replay for it also.\n",
    "            if done:\n",
    "                critic_replay.append( [new_state, float(new_reward)] )\n",
    "            \n",
    "            # Build the update for the Actor. The actor is updated\n",
    "            # by using the difference of the value the critic\n",
    "            # placed on the old state vs. the value the critic\n",
    "            # places on the new state.. encouraging the actor\n",
    "            # to move into more valuable states.\n",
    "            actor_delta = new_val - orig_val                \n",
    "            actor_replay.append([orig_state, action, actor_delta])\n",
    "                    \n",
    "            # Critic Replays...\n",
    "            while(len(critic_replay) > buffer): # Trim replay buffer\n",
    "                critic_replay.pop(0)\n",
    "            # Start training when we have enough samples.\n",
    "            if(len(critic_replay) >= buffer):\n",
    "                minibatch = random.sample(critic_replay, batchSize)\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                for memory in minibatch:\n",
    "                    m_state, m_value = memory\n",
    "                    y = np.empty([1])\n",
    "                    y[0] = m_value\n",
    "                    X_train.append(m_state.reshape((OBSERVATION_SPACE,)))\n",
    "                    y_train.append(y.reshape((1,)))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                critic_model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "            \n",
    "            # Actor Replays...\n",
    "            while(len(actor_replay) > buffer):\n",
    "                actor_replay.pop(0)                \n",
    "            if(len(actor_replay) >= buffer):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                minibatch = random.sample(actor_replay, batchSize)\n",
    "                for memory in minibatch:\n",
    "                    m_orig_state, m_action, m_value = memory\n",
    "                    old_qval = actor_model.predict( m_orig_state.reshape(1,OBSERVATION_SPACE,) )\n",
    "                    y = np.zeros(( 1, ACTION_SPACE ))\n",
    "                    y[:] = old_qval[:]\n",
    "                    y[0][m_action] = m_value\n",
    "                    X_train.append(m_orig_state.reshape((OBSERVATION_SPACE,)))\n",
    "                    y_train.append(y.reshape((ACTION_SPACE,)))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                actor_model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "\n",
    "            # Bookkeeping at the end of the turn.\n",
    "            observation = new_observation\n",
    "            reward = new_reward\n",
    "            move_counter+=1\n",
    "            if done:\n",
    "                if new_reward > 0 : # Win\n",
    "                    wins += 1\n",
    "                else: # Loss\n",
    "                    losses += 1\n",
    "        # Finised Epoch\n",
    "        clear_output(wait=True)\n",
    "        print(\"Game #: %s\" % (i,))\n",
    "        print(\"Moves this round %s\" % move_counter)\n",
    "        print(\"Final Position:\")\n",
    "        env.render()\n",
    "        print(\"Wins/Losses %s/%s\" % (wins, losses))\n",
    "        if epsilon > min_epsilon:\n",
    "            epsilon -= (1/epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_onehot(OBSERVATION_SPACE,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now train the Actor/Critic for a number of epoch's which seems to give decent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #: 82\n",
      "Moves this round 13\n",
      "Final Position:\n",
      "  (Left)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFF\u001b[41mH\u001b[0mFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "Wins/Losses 0/83\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-655b4d9311b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trainer()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0bc9fa7040f7>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(epochs, batchSize, gamma, epsilon, min_epsilon, buffer)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mm_orig_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                     \u001b[0mold_qval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mm_orig_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOBSERVATION_SPACE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACTION_SPACE\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_qval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1585\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;31m# Captures the name of a node in an error status.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gmunoz/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mbuild_results\u001b[0;34m(self, session, tensor_values)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;31m# If the fetch was in the feeds, use the fed value, otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# use the returned value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m           \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can examine what the value network has learned - and the values it has placed on any given location on the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEZCAYAAABVWdSPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x78d7748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "plot_value(STATEGRID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the value network has placed a high value on the winning final position. That value equaling the reward gained when in that position. It also places a very low value on the 'hole' positions. Makes sense. Then we can see that the network places ever growing value on positions which move us closer to the winning position. Thus the value network can express to the policy network that a move which moves us closer to the winning position is more valuable. Lets take a look at what the policy network has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "[['>' 'v' 'v' '>' '^' '>' 'v' 'v']\n",
      " ['>' '>' '>' '>' 'v' 'v' 'v' 'v']\n",
      " ['^' '^' '^' '<' '>' '>' 'v' 'v']\n",
      " ['>' '^' '>' '>' 'v' '^' '>' 'v']\n",
      " ['>' '^' '^' 'v' '>' '>' '>' 'v']\n",
      " ['^' '^' '<' '>' '^' '^' '>' 'v']\n",
      " ['<' '^' '^' '^' 'v' '^' '^' 'v']\n",
      " ['^' '>' '>' '>' '>' '<' '^' '^']]\n"
     ]
    }
   ],
   "source": [
    "# Maps actions to arrows to indicate move direction.\n",
    "A2A=['<','v','>','^']\n",
    "def show_policy(initial_state):\n",
    "    grid = np.zeros((OBS_SQR,OBS_SQR), dtype='<U2')\n",
    "    #working_state = initial_state.copy()\n",
    "    #p = findLoc(working_state, np.array([0,0,0,1]))\n",
    "   #working_state[p[0],p[1]] = np.array([0,0,0,0])\n",
    "    for x in range(0,OBS_SQR):\n",
    "        for y in range(0,OBS_SQR):\n",
    "            #for a in range(0, 4):\n",
    "            my_state = initial_state.copy()\n",
    "            my_state[x,y] = 1\n",
    "            #\n",
    "            obs_predict = my_state.reshape(1,OBSERVATION_SPACE,)\n",
    "            qval = actor_model.predict(obs_predict)\n",
    "            #print(obs_predict)\n",
    "            \n",
    "            action = (np.argmax(qval))\n",
    "            grid[x,y] = A2A[action]\n",
    "    grid\n",
    "    return grid\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "print(show_policy(STATEGRID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll have our learner show us what it has learned. It is important to note, that when testing, we only need the actor/policy network. The critic network is not involved. The Actor has learned the correct policy/moves as it trains on the values supplied by the critic network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "v\n",
      "SFFFFFFF\n",
      "F\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      ">\n",
      "SFFFFFFF\n",
      "FF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      ">\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      ">\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "v\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFH\u001b[41mF\u001b[0mFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      ">\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHF\u001b[41mF\u001b[0mFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      ">\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFF\u001b[41mF\u001b[0mF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "v\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFH\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      ">\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "v\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "v\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "v\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "v\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n",
      "  (Down)\n"
     ]
    }
   ],
   "source": [
    "def play(render_every_step=False):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    reward = 0.0\n",
    "    max_moves = 40\n",
    "    move_counter = 0\n",
    "    while not done and move_counter < max_moves:\n",
    "        state = to_onehot(OBSERVATION_SPACE,observation)\n",
    "        qval = actor_model.predict( state.reshape(1,OBSERVATION_SPACE) )\n",
    "        action = (np.argmax(qval))\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print(A2A[action])\n",
    "        if render_every_step:\n",
    "            env.render()\n",
    "        move_counter += 1\n",
    "    env.render()\n",
    "\n",
    "play(render_every_step=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We've demonstrated using an actor-critic learner to solve a toy gridworld problem. I hope this serves as a good jumping off point for folks trying to understand Actor/Critic, or other RL methods which separate the Policy network from the Value network. If you have questions or comments please leave them below!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
